{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classifier with EfficientNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0t_d9PQmnCR"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kxIt6sMKSNz"
      },
      "source": [
        "!rm tredence_chest_dataset.zip\n",
        "!wget https://he-public-data.s3.ap-southeast-1.amazonaws.com/tredence_chest_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqse0jXXKY2i"
      },
      "source": [
        "!rm -rf dataset\n",
        "!rm -rf prepped\n",
        "!unzip tredence_chest_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXJ4jRUjTFIx"
      },
      "source": [
        "!ls dataset/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKCwvqlaMW2G"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def mk_if_not(path):\n",
        "    try:\n",
        "        os.system('rm -rf '+ path)\n",
        "        os.mkdir(path)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "mk_if_not('prepped')\n",
        "mk_if_not('prepped/train')\n",
        "mk_if_not('prepped/train/nofinding')\n",
        "mk_if_not('prepped/train/cardiomegaly')\n",
        "mk_if_not('prepped/val')\n",
        "mk_if_not('prepped/val/nofinding')\n",
        "mk_if_not('prepped/val/cardiomegaly')\n",
        "mk_if_not('prepped/test')\n",
        "mk_if_not('prepped/test/nofinding')\n",
        "mk_if_not('prepped/test/cardiomegaly')\n",
        "\n",
        "def get_label(path):\n",
        "    data = {}\n",
        "    with open(path) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        line_count = 0\n",
        "        for row in csv_reader:\n",
        "            if line_count == 0:\n",
        "                pass\n",
        "                line_count += 1\n",
        "            else:\n",
        "                data[row[0]] = \"\".join(row[1].split()).lower()\n",
        "                line_count += 1\n",
        "        assert line_count == len(data) + 1\n",
        "    return data\n",
        "\n",
        "def split_and_dump(split):\n",
        "    if split == \"train\":\n",
        "        label = list(get_label('dataset/train.csv').items())\n",
        "        split = (6 * len(label)) // 7\n",
        "        train, val = label[:split], label[split:]\n",
        "        print(set([x[1] for x in label]), len(train), len(val))\n",
        "        for sp, f in [('train', train), ('val', val)]:\n",
        "            for k, v in f:\n",
        "                os.system(\"cp dataset/train/\" + k + \" prepped/\" + sp + \"/\" + v + \"/\"+ k)\n",
        "    else:\n",
        "        assert split == \"test\"\n",
        "        test = label = list(get_label('dataset/test.csv').items())\n",
        "        print(set([x[1] for x in label]), len(test))\n",
        "        for k, _ in test:\n",
        "            if int(k.split('_')[1].split('.')[0]) < 2:\n",
        "                os.system(\"cp dataset/test/\" + k + \" prepped/test/nofinding/\" + k)\n",
        "            else:\n",
        "                os.system(\"cp dataset/test/\" + k + \" prepped/test/cardiomegaly/\" + k)\n",
        "\n",
        "split_and_dump(\"train\")\n",
        "split_and_dump(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_QfpW77SRb6"
      },
      "source": [
        "import os\n",
        "for x in ['test', 'train', 'val']:\n",
        "    print(x + '/cardiomegaly:', len(os.listdir('prepped/' + x.strip() + '/cardiomegaly')))\n",
        "    print(x + '/nofinding   :', len(os.listdir('prepped/' + x.strip() + '/nofinding')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A60Bk2LPQzio"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj5GMy2v6I1L"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import torch.nn.functional as F \n",
        "import torch \n",
        "import numpy as np \n",
        "\n",
        "def show_image(image,label,get_denormalize = True):\n",
        "    \n",
        "    image = image.permute(1,2,0)\n",
        "    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n",
        "    std = torch.FloatTensor([0.229, 0.224, 0.225])\n",
        "    \n",
        "    if get_denormalize == True:\n",
        "        image = image*std + mean\n",
        "        image = np.clip(image,0,1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(label)\n",
        "        \n",
        "    else: \n",
        "        plt.imshow(image)\n",
        "        plt.title(label)\n",
        "\n",
        "def show_grid(image,title = None):\n",
        "    \n",
        "    image = image.permute(1,2,0)\n",
        "    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n",
        "    std = torch.FloatTensor([0.229, 0.224, 0.225])\n",
        "    \n",
        "    image = image*std + mean\n",
        "    image = np.clip(image,0,1)\n",
        "    \n",
        "    plt.figure(figsize=[15, 15])\n",
        "    plt.imshow(image)\n",
        "    if title != None:\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "def accuracy(y_pred,y_true):\n",
        "    y_pred = F.softmax(y_pred,dim = 1)\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "\n",
        "def view_classify(image,ps,label):\n",
        "    \n",
        "    class_name = ['cardiomegaly', 'nofinding']\n",
        "    classes = np.array(class_name)\n",
        "\n",
        "    ps = ps.cpu().data.numpy().squeeze()\n",
        "    \n",
        "    image = image.permute(1,2,0)\n",
        "    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n",
        "    std = torch.FloatTensor([0.229, 0.224, 0.225])\n",
        "    \n",
        "    \n",
        "    image = image*std + mean\n",
        "    img = np.clip(image,0,1)\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(8,12), ncols=2)\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title('Ground Truth : {}'.format(class_name[label]))\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(classes, ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(classes)\n",
        "    ax2.set_yticklabels(classes)\n",
        "    ax2.set_title('Predicted Class')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dEg609uq6rl"
      },
      "source": [
        "class CFG:\n",
        "\n",
        "  epochs = 5                              # No. of epochs for training the model\n",
        "  lr = 0.0005                              # Learning rate\n",
        "  batch_size = 16                         # Batch Size for Dataset\n",
        "\n",
        "  model_name = 'tf_efficientnet_b4_ns'    # Model name (we are going to import model from timm)\n",
        "  img_size = 224                          # Resize all the images to be 224 by 224\n",
        "\n",
        "  # going to be used for loading dataset\n",
        "  train_path    = '/content/prepped/train'\n",
        "  validate_path = '/content/prepped/val'\n",
        "  test_path     = '/content/prepped/test'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"On which device we are on:{}\".format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4iM6KNd5GZL"
      },
      "source": [
        "from torchvision import transforms as T,datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPKrJsI66gEA"
      },
      "source": [
        "train_transform = T.Compose([\n",
        "                             \n",
        "                             T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n",
        "                             T.RandomRotation(degrees=(-20,+20)), #Randomly Rotate Images by +/- 20 degrees, Image argumentation for each epoch\n",
        "                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n",
        "                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n",
        "\n",
        "])\n",
        "\n",
        "validate_transform = T.Compose([\n",
        "                             \n",
        "                             T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n",
        "                             #T.RandomRotation(degrees=(-20,+20)), #NO need for validation\n",
        "                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n",
        "                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n",
        "\n",
        "])\n",
        "\n",
        "test_transform = T.Compose([\n",
        "                             \n",
        "                             T.Resize(size=(CFG.img_size,CFG.img_size)), # Resizing the image to be 224 by 224\n",
        "                             #T.RandomRotation(degrees=(-20,+20)), #NO need for validation\n",
        "                             T.ToTensor(), #converting the dimension from (height,weight,channel) to (channel,height,weight) convention of PyTorch\n",
        "                             T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH_iwvjLHy0P"
      },
      "source": [
        "trainset=datasets.ImageFolder(CFG.train_path,transform=train_transform)\n",
        "print(\"Trainset Size:  {}\".format(len(trainset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fViQ8qV5PGjS"
      },
      "source": [
        "validateset=datasets.ImageFolder(CFG.validate_path,transform=validate_transform)\n",
        "print(\"validateset Size:  {}\".format(len(validateset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_meyiYhfI1YY"
      },
      "source": [
        "testset=datasets.ImageFolder(CFG.test_path,transform=test_transform)\n",
        "print(\"testset Size:  {}\".format(len(testset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrQlINDPJMoq"
      },
      "source": [
        "img,label = trainset[10]\n",
        "#print(trainset.class_to_idx)\n",
        "\n",
        "class_name =[\"cardiomegaly\",\"nofinding\"]\n",
        "show_image(img,class_name[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhhiZ73iR1k5"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MwFHrYDONl2"
      },
      "source": [
        "trainloader = DataLoader(trainset,batch_size=CFG.batch_size,shuffle=True)\n",
        "print(\"No. of batches in trainloader:{}\".format(len(trainloader))) #Trainset Size:  1400 / batch_size: 16 = 88(No. of batches in trainloader) \n",
        "print(\"No. of Total examples:{}\".format(len(trainloader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzm8yW_bXSEr"
      },
      "source": [
        "validationloader = DataLoader(validateset,batch_size=CFG.batch_size,shuffle=True)\n",
        "print(\"No. of batches in validationloader:{}\".format(len(validationloader))) #validationset Size:  16 / batch_size: 16 = 1(No. of batches in validationloader) \n",
        "print(\"No. of Total examples:{}\".format(len(validationloader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSEUnFqBXINe"
      },
      "source": [
        "testloader = DataLoader(testset,batch_size=CFG.batch_size,shuffle=False)\n",
        "print(\"No. of batches in testloader:{}\".format(len(testloader))) #testset Size:  624 / batch_size: 16 = 39(No. of batches in testloader) \n",
        "print(\"No. of Total examples:{}\".format(len(testloader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-3a0mpXdbv"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images,labels = dataiter.next()\n",
        "\n",
        "out = make_grid(images,nrow=4)\n",
        "\n",
        "show_grid(out,title = [class_name[x] for x in labels])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCl1kJ4dcCds"
      },
      "source": [
        "!pip install timm # install PyTorch Image Models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYuYgY2SZp5S"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import timm # PyTorch Image Models\n",
        "\n",
        "model = timm.create_model(CFG.model_name,pretrained=True) #load pretrained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blSmZcGRcSiH"
      },
      "source": [
        "!rm ColabPneumoniaModel.pt\n",
        "!wget https://github.com/Ayushk4/semStance/releases/download/tagg/ColabPneumoniaModel.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWXBddDCXg8a"
      },
      "source": [
        "prev_state_dict = torch.load('ColabPneumoniaModel.pt')\n",
        "# prev_state_dict['classifier.0.weight'].shape for i in ['0','3','5']\n",
        "del prev_state_dict['classifier.0.weight']\n",
        "del prev_state_dict['classifier.0.bias']\n",
        "del prev_state_dict['classifier.3.weight']\n",
        "del prev_state_dict['classifier.3.bias']\n",
        "del prev_state_dict['classifier.5.weight']\n",
        "del prev_state_dict['classifier.5.bias']\n",
        "prev_state_dict['classifier.weight'] = torch.randn(model.classifier.weight.shape)\n",
        "prev_state_dict['classifier.bias'] = torch.randn(model.classifier.bias.shape)\n",
        "# print(type(prev_state_dict))\n",
        "\n",
        "# print(model.classifier.weight.shape)\n",
        "model.load_state_dict(prev_state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxWUtvIcckDg"
      },
      "source": [
        "#let's update the pretarined model:\n",
        "for param in model.parameters():\n",
        "  param.requires_grad=False\n",
        "\n",
        "#orginally, it was:\n",
        "#(classifier): Linear(in_features=1792, out_features=1000, bias=True)\n",
        "\n",
        "\n",
        "#we are updating it as a 2-class classifier:\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=1792, out_features=625), #1792 is the orginal in_features\n",
        "    nn.ReLU(), #ReLu to be the activation function\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(in_features=625, out_features=256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=256, out_features=2), \n",
        ")\n",
        "\n",
        "model\n",
        "# print()\n",
        "# after updatingnow it becomes:\n",
        "#(classifier): Sequential(\n",
        "#    (0): Linear(in_features=1792, out_features=625, bias=True)\n",
        "#    (1): ReLU()\n",
        "#    (2): Dropout(p=0.3, inplace=False)\n",
        "#    (3): Linear(in_features=625, out_features=256, bias=True)\n",
        "#    (4): ReLU()\n",
        "#    (5): Linear(in_features=256, out_features=2, bias=True)\n",
        "#  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXUTiMmLhrgI"
      },
      "source": [
        "from torchsummary import  summary\n",
        "model.to(device) # move the model to GPU\n",
        "summary(model,input_size=(3,224,224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0mKfl38NYkb"
      },
      "source": [
        "class MyTrainer():\n",
        "    \n",
        "    def __init__(self,criterion = None,optimizer = None,schedular = None):\n",
        "        \n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.schedular = schedular\n",
        "    \n",
        "    def train_batch_loop(self,model,trainloader):\n",
        "        \n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        for images,labels in tqdm(trainloader): \n",
        "            \n",
        "            # move the data to CPU\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            logits = model(images)\n",
        "            loss = self.criterion(logits,labels)\n",
        "            \n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            train_acc += accuracy(logits,labels)\n",
        "            \n",
        "        return train_loss / len(trainloader), train_acc / len(trainloader) \n",
        "\n",
        "    \n",
        "    def valid_batch_loop(self,model,validloader):\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for images,labels in tqdm(validloader):\n",
        "            \n",
        "            # move the data to CPU\n",
        "            images = images.to(device) \n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            logits = model(images)\n",
        "            loss = self.criterion(logits,labels)\n",
        "            \n",
        "            valid_loss += loss.item()\n",
        "            valid_acc += accuracy(logits,labels)\n",
        "            \n",
        "        return valid_loss / len(validloader), valid_acc / len(validloader)\n",
        "            \n",
        "        \n",
        "    def fit(self,model,trainloader,validloader,epochs):\n",
        "        \n",
        "        valid_min_loss = np.Inf \n",
        "        \n",
        "        for i in range(epochs):\n",
        "            \n",
        "            model.train() # this turn on dropout\n",
        "            avg_train_loss, avg_train_acc = self.train_batch_loop(model,trainloader) ###\n",
        "            \n",
        "            model.eval()  # this turns off the dropout lapyer and batch norm\n",
        "            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model,validloader) ###\n",
        "            \n",
        "            if avg_valid_loss <= valid_min_loss :\n",
        "                print(\"Valid_loss decreased {} --> {}\".format(valid_min_loss,avg_valid_loss))\n",
        "                torch.save(model.state_dict(),'saved.pt')\n",
        "                valid_min_loss = avg_valid_loss\n",
        "\n",
        "                \n",
        "            print(\"Epoch : {} Train Loss : {:.6f} Train Acc : {:.6f}\".format(i+1, avg_train_loss, avg_train_acc))\n",
        "            print(\"Epoch : {} Valid Loss : {:.6f} Valid Acc : {:.6f}\".format(i+1, avg_valid_loss, avg_valid_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be4yV5tIU2u1"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = CFG.lr)\n",
        "\n",
        "trainer = MyTrainer(criterion,optimizer)\n",
        "trainer.fit(model,trainloader,validationloader,epochs = CFG.epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jH-gTyKb6rm"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/saved.pt'))\n",
        "model.eval()\n",
        "\n",
        "# avg_test_loss, avg_test_acc = trainer.valid_batch_loop(model,testloader)\n",
        "\n",
        "\n",
        "# print(\"Test Loss : {}\".format(avg_test_loss))\n",
        "# print(\"Test Acc : {}\".format(avg_test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVcpPCTdgUeP"
      },
      "source": [
        "testset[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFgA4PZacn67"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "for i, _ in testset:\n",
        "image,label = testset[15]\n",
        "\n",
        "ps = model(image.to(device).unsqueeze(0))\n",
        "ps = F.softmax(ps,dim = 1)\n",
        "ps.argmax().detach().cpu()\n",
        "# view_classify(image,ps,label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeS-55IUlsoR"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "image,label = testset[1]\n",
        "\n",
        "ps = model(image.to(device).unsqueeze(0))\n",
        "ps = F.softmax(ps,dim = 1)\n",
        "\n",
        "view_classify(image,ps,label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MGcHENElu-e"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "image,label = testset[14]\n",
        "\n",
        "ps = model(image.to(device).unsqueeze(0))\n",
        "ps = F.softmax(ps,dim = 1)\n",
        "\n",
        "view_classify(image,ps,label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfHOJM2olzDT"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "mapper = {0:'Cardiomegaly', 1:'No Finding'}\n",
        "strs = [\"imageID,disease\"]\n",
        "for i in range(len(testset)):\n",
        "    image,_ = testset[i]\n",
        "    filename = testset.samples[i][0]\n",
        "\n",
        "    ps = model(image.to(device).unsqueeze(0))\n",
        "    ps = F.softmax(ps,dim = 1)\n",
        "    strs.append(filename.split('/')[-1] + \",\" + mapper[ps.argmax().cpu().tolist()])\n",
        "\n",
        "# view_classify(image,ps,label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZBBnv9XlqqM"
      },
      "source": [
        "open(\"sample_submission.csv\", 'w+').write(\"\\n\".join(strs).strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZeF_m6reNE0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RfOWvRhkoFY"
      },
      "source": [
        "CFG.train_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDIVdQdQlVMF"
      },
      "source": [
        "testset.samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH7f4By3oIqH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}